model:
  name: ResNet50
  architecture:
    layers: 50
    dropout: 0.5
  
training:
  epochs: 50
  batch_size: 32
  learning_rate: 0.001
  optimizer: Adam
  
dataset:
  name: CIFAR-10
  train_size: 50000
  val_size: 10000
  
hyperparameters:
  weight_decay: 0.0001
  momentum: 0.9
  lr_schedule: step_decay
  step_size: 20
  gamma: 0.1